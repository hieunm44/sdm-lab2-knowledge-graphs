{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1097db88-affa-416b-8934-6f2d9b9efe6b",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries, modules and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75d50f8f-eb6e-4137-8088-a7c3878b384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import random\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69a514b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Database as Domain to fieldOfStudy when the paper title contains the word \"database\".\n",
    "with open(file = 'data1/dataset.json', encoding = 'utf-8') as inputfile:\n",
    "    df = json.load(inputfile)\n",
    "\n",
    "with open(file = 'data1/dataset2.json', mode = 'w+', encoding = 'utf-8') as outputfile:\n",
    "    df2 = df\n",
    "    for i in range(len(df2)):\n",
    "        details = df2[i]['_data']  \n",
    "        paperTitle = details['title']\n",
    "        if 'database' in paperTitle.lower():\n",
    "            if details['fieldsOfStudy']:\n",
    "                details['fieldsOfStudy'].append('Database')\n",
    "            else:\n",
    "                details['fieldsOfStudy'] = ['Database']\n",
    "    json.dump(df2, outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c06104-b018-4c2b-b58c-5762c750248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data1/dataset2.json', encoding='utf-8') as inputfile:\n",
    "    df = json.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e967c89-efae-4d1b-abb4-f39d8fd13360",
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences = []\n",
    "conferenceUrls = []\n",
    "\n",
    "journals = []\n",
    "journalUrls = []\n",
    "\n",
    "authors = []\n",
    "authorUrls = []\n",
    "\n",
    "domains = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    details = df[i]['_data']  \n",
    "    if details['publicationVenue']:\n",
    "        if 'type' in details['publicationVenue']:\n",
    "            if details['publicationVenue']['type'] == 'journal':\n",
    "                jName = details['publicationVenue']['name']\n",
    "                myId = details['publicationVenue']['id']\n",
    "                if jName not in journals:\n",
    "                    journals.append(jName)\n",
    "                    journalUrls.append(myId)\n",
    "            elif details['publicationVenue']['type'] == 'conference':\n",
    "                cName = details['publicationVenue']['name']\n",
    "                myId = details['publicationVenue']['id']\n",
    "                if cName not in conferences:\n",
    "                    conferences.append(cName)\n",
    "                    conferenceUrls.append(myId)\n",
    "    if details['authors']:\n",
    "        for i in range(len(details['authors'])):\n",
    "            aName = details['authors'][i]['name']\n",
    "            myId = details['authors'][i]['authorId']\n",
    "            if aName not in authors:\n",
    "                authors.append(aName)\n",
    "                authorUrls.append(str(myId))\n",
    "    if details['fieldsOfStudy']:\n",
    "        for i in details['fieldsOfStudy']:\n",
    "            if i not in domains:\n",
    "                domains.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86751277-d94e-4928-acbe-3d7b2a4df0cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Proceedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81fce26f-52b3-491f-9158-6bdd12a0b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning proceedings ids\n",
    "proceedingChoices = []\n",
    "proceedingYears = []\n",
    "ids = []\n",
    "for i in range(len(conferences)):\n",
    "    ids.append('cp'+str(i)) # stands for conferenceProceedings\n",
    "    \n",
    "    # Creating proceeding names as integers\n",
    "    proceedingChoices.append('proceeding' + str(i))\n",
    "    \n",
    "    # Creating proceedings year as a random year between 2000 and 2024\n",
    "    proceedingYears.append(random.randint(2001, 2024))\n",
    "        \n",
    "proceedings_df = pd.DataFrame(ids, columns = ['proceedingId'])\n",
    "proceedings_df['proceedingName'] = proceedingChoices\n",
    "proceedings_df['proceedingYear'] = proceedingYears\n",
    "proceedings_df.to_csv('data1/proceedings.csv',index = False, header = True, mode = 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aee8257-9054-4719-8cc9-8709bc9bb604",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Conferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36758d36-e114-48d7-8c93-e2320fb6fcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign conference ids which can be added to the uri's in the graph\n",
    "\n",
    "ids = []\n",
    "proceedings = []\n",
    "for i in range(len(conferences)):\n",
    "    ids.append('c'+str(i))\n",
    "\n",
    "conferences_df = pd.DataFrame(ids, columns = ['conferenceId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeeda63e-bc57-48f9-8bc4-68a03dd2fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning conference subclasses\n",
    "cTypes = ['workshop','mainConference']\n",
    "\n",
    "conferenceTypes = []\n",
    "conferenceTypes = random.choices(cTypes, weights=[0.25,0.75], k=len(conferences_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8701dd2d-196e-45b7-bbda-bca837c19096",
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_df['conferenceUrl'] = conferenceUrls\n",
    "conferences_df['conferenceTitle'] = conferences\n",
    "conferences_df['conferenceType'] = conferenceTypes\n",
    "\n",
    "# Creating proceedings data for conferences\n",
    "conferences_df['conferenceProceedingIds'] = proceedings_df['proceedingId']\n",
    "conferences_df.to_csv('data1/conferences.csv', index = False, header = True, mode = 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106bb40e-f207-457b-b2f5-e35b8709796b",
   "metadata": {},
   "source": [
    "#### ConferenceProceedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5118cd68-2503-4a00-bc0f-3b45e4ee1bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conferenceProceedings_df = conferences_df.merge(\n",
    "    proceedings_df,\n",
    "    how = 'inner',\n",
    "    left_on = ['conferenceProceedingIds'],\n",
    "    right_on = ['proceedingId']\n",
    "    ).drop(columns = ['proceedingId'], axis = 1)\n",
    "conferenceProceedings_df.to_csv('data1/conferenceProceedings.csv', index = False, header = True, mode = 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290facbe-dae5-405d-adbd-9845086482bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d729766a-dca9-4c0f-8f3b-2cb275e8a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning proceedings ids\n",
    "volumeChoices = []\n",
    "volumeYears = []\n",
    "ids = []\n",
    "for i in range(len(journals)):\n",
    "    ids.append('jv'+str(i)) # stands for journalVolume\n",
    "    \n",
    "    # Creating proceedings attributes\n",
    "    volumeChoices.append('journal' + str(i))\n",
    "    volumeYears.append(random.randint(2001, 2024))\n",
    "        \n",
    "volumes_df = pd.DataFrame(ids, columns = ['volumeId'])\n",
    "volumes_df['volumeName'] = volumeChoices\n",
    "volumes_df['volumeYear'] = volumeYears\n",
    "volumes_df.to_csv('data1/volumes.csv',index = False, header = True, mode = 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3367214f-a482-4d4d-981e-f9a4476fa1e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ececeec9-ce8c-4098-bb80-5bdd7f0006b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning journals ids which can be added to the uri's in the graph\n",
    "ids = []\n",
    "volumes = []\n",
    "for i in range(len(journals)):\n",
    "    ids.append('j'+str(i))\n",
    "\n",
    "journals_df = pd.DataFrame(ids, columns = ['journalId'])\n",
    "journals_df['journalUrl'] = journalUrls\n",
    "journals_df['journalTitle'] = journals\n",
    "\n",
    "# Creating volumes data for journals\n",
    "journals_df['journalVolumeIds'] = volumes_df['volumeId']\n",
    "journals_df.to_csv('data1/journals.csv',index = False, header = True, mode = 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5409aa16-1d73-4d21-a9c6-93cb37e64043",
   "metadata": {},
   "source": [
    "#### JournalVolumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8140561-5bf9-435e-b062-a3a247acbccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "journalVolumes_df = journals_df.merge(\n",
    "    volumes_df,\n",
    "    how = 'inner',\n",
    "    left_on = ['journalVolumeIds'],\n",
    "    right_on = ['volumeId']\n",
    "    ).drop(columns = ['volumeId'], axis = 1)\n",
    "journalVolumes_df.to_csv('data1/journalVolumes.csv',index = False, header = True, mode = 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50af79f4-5538-4485-812e-e66e41faa132",
   "metadata": {},
   "source": [
    "#### Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f90d9d95-7df9-4792-a5bf-c85bb6c71250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning author ids which can be added to the uri's in the graph\n",
    "ids = []\n",
    "for i in range(len(authors)):\n",
    "    ids.append('a'+str(i))\n",
    "\n",
    "authors_df = pd.DataFrame(ids, columns = ['authorId'])\n",
    "authors_df['authorUrl'] = authorUrls\n",
    "authors_df['authorName'] = authors\n",
    "authors_df.to_csv('data1/authors.csv',index = False, header = True, mode = 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f566c3-8379-45dd-b267-dd8caa2e6016",
   "metadata": {},
   "source": [
    "#### Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c119ba8-9ee8-4281-bd2e-15d3fa684e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning domain ids which can be added to the uri's in the graph\n",
    "ids = []\n",
    "for i in range(len(domains)):\n",
    "    ids.append('d'+str(i))\n",
    "\n",
    "domain_df = pd.DataFrame(ids, columns = ['domainId'])\n",
    "domain_df['domainName'] = domains\n",
    "domain_df.to_csv('data1/domains.csv',index = False, header = True, mode = 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ed274c-5f47-4bc1-9b04-919d3b59c8f6",
   "metadata": {},
   "source": [
    "### Collecting information about papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ed77e71-eed7-4b3d-9613-e5c95e869bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = []\n",
    "\n",
    "paperUrlNum = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    paperCurr = [] \n",
    "    details = df[i]['_data']\n",
    "    \n",
    "    currPaperUrlNum = 'p'+str(paperUrlNum)\n",
    "    paperCurr.append(currPaperUrlNum)\n",
    "    paperCurr.append(details['paperId'])\n",
    "    \n",
    "    if details['publicationVenue']:\n",
    "        if 'type' in details['publicationVenue']:\n",
    "            if details['publicationVenue']['type'] == 'journal':\n",
    "                jName = details['publicationVenue']['name']\n",
    "                paperCurr.append(journals_df[journals_df['journalTitle'] == jName]['journalId'].values[0])\n",
    "                paperCurr.append(jName)\n",
    "            elif details['publicationVenue']['type'] == 'conference':\n",
    "                cName = details['publicationVenue']['name']\n",
    "                paperCurr.append(conferences_df[conferences_df['conferenceTitle'] == cName]['conferenceId'].values[0])\n",
    "                paperCurr.append(cName)\n",
    "\n",
    "            else:\n",
    "                paperCurr.append('None')\n",
    "                paperCurr.append('None')\n",
    "        else:\n",
    "            paperCurr.append('None')\n",
    "            paperCurr.append('None')\n",
    "    else:\n",
    "        paperCurr.append('None') # conferenceJournalUrl\n",
    "        paperCurr.append('None') # conferenceJournal\n",
    "    \n",
    "    paperCurr.append(details['title'])\n",
    "    paperCurr.append(details['abstract'])\n",
    "    paperUrlNum += 1\n",
    "    papers.append(paperCurr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b27679a4-3ebf-4128-bdb9-e33892c01de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "paperColumns = ['paperId','paperUrl','conferenceJournalId','conferenceJournalTitle','paperTitle','paperAbstract']\n",
    "\n",
    "papers_df = pd.DataFrame(papers, columns = paperColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6b592c8-75a5-4445-9891-bf2644ebeadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign paper subclasses\n",
    "# Assign type poster if not a conference/journal\n",
    "# Else, randomly choose from pTypes\n",
    "\n",
    "paperTypes = []\n",
    "pTypes = ['fullPaper']\n",
    "for index, row in papers_df.iterrows():\n",
    "    if row['conferenceJournalId'] == 'None':\n",
    "        paperTypes.append('poster')\n",
    "    else:\n",
    "        paperTypes.append(random.choice(pTypes))\n",
    "papers_df['paperType'] = paperTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50ebd2df-bd60-4d2c-a4d4-844ff1172845",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df['conferenceJournalId'] = papers_df.apply(lambda x: random.choice(conferences_df.conferenceId) if x['paperType'] == 'poster' else x['conferenceJournalId'], axis = 1)\n",
    "papers_df['conferenceJournalTitle'] = papers_df.apply(lambda x: conferences_df[conferences_df['conferenceId'] == x['conferenceJournalId']]['conferenceTitle'].item() if x['paperType'] == 'poster' else x['conferenceJournalTitle'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b356f5a7-13a4-41bc-9e2c-9fa4f723fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get proceedings and volumes for conferences/journals for each paper\n",
    "procVols = []\n",
    "for k in range(len(papers_df['paperId'])):\n",
    "    currConfJourId = papers_df['conferenceJournalId'][k]\n",
    "    if currConfJourId[0] == 'c':\n",
    "        getProcVol = conferences_df[conferences_df['conferenceId'] == currConfJourId]['conferenceProceedingIds'].item()\n",
    "    else:\n",
    "        getProcVol = journals_df[journals_df['journalId'] == currConfJourId]['journalVolumeIds'].item()\n",
    "    procVols.append(getProcVol)\n",
    "papers_df['proceedingsVolumesIds'] = procVols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5726ac3-810f-43b2-a7f6-1a75870e5268",
   "metadata": {},
   "source": [
    "Since, some of the paper's abstract is null, we are imputing with a default value of \"Abstract content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5c2921b-a773-41f7-aa98-08c48ad31a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute None values for abstract\n",
    "papers_df['paperAbstract'] = papers_df.apply(lambda x: 'Abstract content' if x['paperAbstract'] == None else x['paperAbstract'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5052b386-62b2-4407-8311-ee22bebe129f",
   "metadata": {},
   "source": [
    "Imputing conferenceJournalId as randomly chosen conference from the list of conferences and corresponding conferenceJournalTitle for the paperType as poster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94564970-900d-426e-a9f1-3d76ac8ddafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df.to_csv('data1/papers.csv',index = False, header = True, mode = 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40310f57-9e7c-4d58-8621-199f1e1f0c33",
   "metadata": {},
   "source": [
    "### Creating authors domain relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52419b04-74ae-4c0c-ae9d-6c1e8849f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_ids = []\n",
    "pIds = []\n",
    "\n",
    "paperUrlNum = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    paperCurr = [] \n",
    "    details = df[i]['_data']\n",
    "    \n",
    "    currPaperUrlNum = 'p'+str(paperUrlNum)\n",
    "    \n",
    "    # Adding pId to domainId\n",
    "    if details['fieldsOfStudy']:\n",
    "        for i in range(len(details['fieldsOfStudy'])):\n",
    "            domainId = details['fieldsOfStudy'][i]\n",
    "            domain_ids.append(domainId)\n",
    "            pIds.append(currPaperUrlNum)\n",
    "    paperUrlNum += 1\n",
    "\n",
    "domainsPapers_df = pd.DataFrame(domain_ids, columns = ['domainName'])\n",
    "domainsPapers_df['paperId'] = pIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c3424ed-d970-47db-a73b-2fc0e4ac18cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "domainsPapers_df = domainsPapers_df.merge(\n",
    "                    domain_df,\n",
    "                    how = 'inner',\n",
    "                    left_on = ['domainName'],\n",
    "                    right_on = ['domainName']\n",
    "                    )\n",
    "\n",
    "domainsPapers_df = domainsPapers_df.merge(\n",
    "                    papers_df,\n",
    "                    how = 'inner',\n",
    "                    left_on = ['paperId'],\n",
    "                    right_on = ['paperId']\n",
    "                    )\n",
    "domainsPapers_df.to_csv('data1/domainsPapers.csv',index = False, header = True, mode = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "292f7bc1-9b15-4bcc-a916-e87444c52b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "domainsConferencesJournals_df = domainsPapers_df[['conferenceJournalId', 'proceedingsVolumesIds', 'domainId']]\n",
    "domainsConferencesJournals_df.to_csv('data1/domainsProceedingsVolumes.csv', index = False, header = True, mode = 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67116c09-b6f7-4684-945e-d49323dd76e6",
   "metadata": {},
   "source": [
    "### Creating authors papers relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d33ce0dd-bdcf-4a8a-9f0c-b938fcc11830",
   "metadata": {},
   "outputs": [],
   "source": [
    "aUrlIds = []\n",
    "pIds = []\n",
    "\n",
    "paperUrlNum = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    paperCurr = [] \n",
    "    details = df[i]['_data']\n",
    "    currPaperUrlNum = 'p'+str(paperUrlNum)\n",
    "    \n",
    "    # Appending the pId to authors_df\n",
    "    if details['authors']:\n",
    "        for i in range(len(details['authors'])):\n",
    "            aUrlId = details['authors'][i]['authorId']\n",
    "            aUrlIds.append(str(aUrlId))\n",
    "            pIds.append(currPaperUrlNum)\n",
    "    paperUrlNum += 1\n",
    "\n",
    "authorsPapers_df = pd.DataFrame(aUrlIds, columns = ['authorUrl'])\n",
    "authorsPapers_df['paperId'] = pIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "112ca99e-dacf-443c-b004-79689fef8f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "authorsPapers_df = authorsPapers_df.merge(\n",
    "                    authors_df,\n",
    "                    how = 'inner',\n",
    "                    left_on = ['authorUrl'],\n",
    "                    right_on = ['authorUrl']\n",
    "                    )\n",
    "\n",
    "authorsPapers_df = authorsPapers_df.merge(\n",
    "                    papers_df,\n",
    "                    how = 'inner',\n",
    "                    left_on = ['paperId'],\n",
    "                    right_on = ['paperId']\n",
    "                    )\n",
    "authorsPapers_df.head()\n",
    "authorsPapers_df.to_csv('data1/authorsPapers.csv',index = False, header = True, mode = 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24922f2a-7248-4ee8-9032-bf72c7664bed",
   "metadata": {},
   "source": [
    "### Creating Reviews Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5884f7d3-bb0c-4184-819d-ca774dede7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign ids to reviews for adding to uri's of the graph\n",
    "ids = []\n",
    "for i in range(len(papers_df)):\n",
    "    ids.append('r'+str(i))\n",
    "\n",
    "decisionChoices = ['accepted','rejected']\n",
    "\n",
    "reviews_df = pd.DataFrame(ids, columns = ['reviewId'])\n",
    "reviews_df['paperId'] = papers_df['paperId']\n",
    "reviews_df['reviewText'] = ['Review content'] * len(reviews_df)\n",
    "reviews_df['reviewDecision'] = random.choices(decisionChoices, weights = [0.8, 0.2], k = len(papers_df))\n",
    "reviews_df['reviewDecisionBoolean'] = reviews_df.apply(lambda x: 1 if x['reviewDecision'] == 'accepted' else 0, axis = 1)\n",
    "reviews_df['paperTitle'] = papers_df['paperTitle']\n",
    "reviews_df.to_csv('data1/reviews.csv',index = False, header = True, mode = 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddfddf0-1fd0-4dd0-b526-7e74448a8ab7",
   "metadata": {},
   "source": [
    "### Creating Reviewer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbf4f2d9-6e79-48f8-84f3-fa2260cc4c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_authors = list(authorsPapers_df['authorId'].unique())\n",
    "paperAuthors = authorsPapers_df.groupby('paperId', as_index = False, sort = False)['authorId'].agg(lambda x: [l for l in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fececacc-ce2f-4804-88f4-641879025863",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalPapers = len(papers_df)\n",
    "set_authors = set(all_authors)\n",
    "\n",
    "ids = []\n",
    "submissions = []\n",
    "reviewers = []\n",
    "\n",
    "for i in range(totalPapers * 2):\n",
    "    ids.append('r'+str(i))\n",
    "    submissions.append(papers_df['paperId'][i//2])\n",
    "    \n",
    "    curr_pId = papers_df['paperId'][i//2]\n",
    "    curr_authors = paperAuthors[paperAuthors['paperId'] == curr_pId]['authorId'].tolist()\n",
    "    \n",
    "    availableReviewers = [x for x in set_authors if not x in curr_authors]\n",
    "    reviewers.append(random.choice(availableReviewers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f79540b8-4cc8-456d-8365-44a67b35d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewer (author id: aId) reviews the submission (with id: sId)\n",
    "reviewers_df = pd.DataFrame(ids, columns = ['rId'])\n",
    "reviewers_df['paperId'] = submissions\n",
    "reviewers_df['authorId'] = reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10215116-fc1f-4627-a0b1-4f1555324197",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewers_df = reviewers_df.merge(\n",
    "            authors_df,\n",
    "            how = 'inner',\n",
    "            left_on = ['authorId'],\n",
    "            right_on = ['authorId']\n",
    "            )\n",
    "\n",
    "reviewers_df = reviewers_df.merge(\n",
    "            papers_df,\n",
    "            how = 'inner',\n",
    "            left_on = ['paperId'],\n",
    "            right_on = ['paperId']\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de66b74c-4151-4a6d-90e1-e390ac125d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewers_df.to_csv('data1/reviewers.csv',index = False, header = True, mode = 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2190c5-8469-4076-98fc-2b5a3f143fe2",
   "metadata": {},
   "source": [
    "### Creating chairs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e228bf4-e03f-406e-94d8-e1c18caddb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "confPapers = papers_df[papers_df['conferenceJournalId'].str[:1] == 'c']['conferenceJournalId'].tolist()\n",
    "\n",
    "confPapers_df = pd.DataFrame(confPapers, columns = ['conferenceId'])\n",
    "\n",
    "ids = []\n",
    "for i in range(len(confPapers_df)):\n",
    "    ids.append('chair'+str(i))\n",
    "confPapers_df['chairId'] = ids\n",
    "\n",
    "confPapers_df['authorId'] = random.choices(authors_df['authorId'], k = len(confPapers_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeac4843-9957-4068-b3a2-71610d5e20fd",
   "metadata": {},
   "source": [
    "It is assumed that any author from our database can chair any conference, irrespective of the number of papers written, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4420b72-37f7-49f3-a61c-5f1405a9ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "confPapers_df.to_csv('data1/chairs.csv',index = False, header = True, mode = 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb001d-587c-4635-8d99-be7f97ee94f0",
   "metadata": {},
   "source": [
    "This implies that for author with x id chairs the conference y with c chairId or author x handles the conference y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc60d492-8dbf-45a5-8dd1-e0c27cb3f710",
   "metadata": {},
   "source": [
    "### Creating editors data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54f64a16-43f8-4f48-9097-e3712f092cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jourPapers = papers_df[papers_df['conferenceJournalId'].str[:1] == 'j']['conferenceJournalId'].tolist()\n",
    "\n",
    "jourPapers_df = pd.DataFrame(jourPapers, columns = ['journalId'])\n",
    "\n",
    "ids = []\n",
    "for i in range(len(jourPapers_df)):\n",
    "    ids.append('editor'+str(i))\n",
    "jourPapers_df['editorId'] = ids\n",
    "\n",
    "jourPapers_df['authorId'] = random.choices(authors_df['authorId'], k = len(jourPapers_df))\n",
    "jourPapers_df.to_csv('data1/editors.csv',index = False, header = True, mode = 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e158da-8a70-430a-99db-2d5c07ac0318",
   "metadata": {},
   "source": [
    "It is assumed that any author from our database can chair any conference, irrespective of the number of papers written, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d08ae2-146f-4530-822d-7953e51e8b3d",
   "metadata": {},
   "source": [
    "This implies that for author with x id is the editor of the journal y with e editorId or author x handles the journal y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af715e07-e4bb-429f-9022-8e20696cdfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "jourPapers_df.to_csv('data1/editors.csv',index = False, header = True, mode = 'w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
